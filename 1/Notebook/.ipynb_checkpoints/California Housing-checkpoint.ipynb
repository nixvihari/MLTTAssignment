{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9557aece-926a-4493-a1ae-140caa1e7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f2a72-8cdf-4f14-8834-45a09539f746",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33b2084-0365-4b79-9172-e2dfaa7086c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('../datasets/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85aaddf3-c2d4-4c6c-8fc3-25815cc6003f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5393dc1b-ddc6-4da6-8343-7fa1a546dbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a254e69-9e0c-42a5-88af-3cad7009bb70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Attributes to be Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc1d897-aa3a-4a79-bde7-0aea0b36b7b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude  latitude  housing_median_age  total_rooms  total_bedrooms  population  households  median_income  median_house_value  ocean_proximity\n",
      "False      False     False               False        False           False       False       False          False               False              20433\n",
      "                                                      True            False       False       False          False               False                207\n",
      "Name: count, dtype: int64\n",
      "False    20640\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Missing values\n",
    "print(housing.isna().value_counts())\n",
    "print(housing.duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244702bb-fff0-4833-ba14-12c0e6b13e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_bedrooms\n",
       "False    20433\n",
       "True       207\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['total_bedrooms'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42b949a-8b8f-4690-b43e-d6acc766af84",
   "metadata": {},
   "source": [
    "- From the above code blocks we can see that total bedrooms have 'na' values because it returned true for df.isna() function\n",
    "- Therefore we impute - replace na with meadian values function\n",
    "- No duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c2a6789-cc26-49e9-a9ef-33000ea5d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEAR BAY' '<1H OCEAN' 'INLAND' 'NEAR OCEAN' 'ISLAND']\n",
      "ocean_proximity\n",
      "<1H OCEAN     9136\n",
      "INLAND        6551\n",
      "NEAR OCEAN    2658\n",
      "NEAR BAY      2290\n",
      "ISLAND           5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.unique(housing['ocean_proximity']))\n",
    "print(housing['ocean_proximity'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92466d1f-dc0e-4aed-82fc-a9275a6fa093",
   "metadata": {},
   "source": [
    "We have one ocean proximity which is categorical in nature, and should be encoded in order to be used as a feature. Regular label encoding may be used, but ML algorithms percieve their values in way where closer number values are assumed to be more proximal than farther numbers. Hence we use OneHotEncoding where we make each category as an attribute and have binary values(1 or 0) for every row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c67cb-fc1f-4980-bd7f-6b3346fa1954",
   "metadata": {},
   "source": [
    "### Pipeline Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7713563d-5acb-4abf-ab67-311b58a0f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import logging\n",
    "\n",
    "\n",
    "class NaImputer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, housing):\n",
    "        print('Imputing na values...')\n",
    "        \n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        housing['total_bedrooms'] = imputer.fit_transform(housing[['total_bedrooms']])\n",
    "        \n",
    "        print('Imputed na values.\\n')\n",
    "        \n",
    "        return housing\n",
    "\n",
    "\n",
    "class FeatureEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, housing):\n",
    "        print('OneHotEncoding column, ocean_proximity ...')\n",
    "        \n",
    "        encoder = OneHotEncoder()\n",
    "        matrix = encoder.fit_transform(housing[['ocean_proximity']]).toarray()\n",
    "        column_names = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
    "        for i in range(len(matrix.T)):\n",
    "            housing[column_names[i]] = matrix.T[i]\n",
    "        \n",
    "        print('New Columns added \\nocean_proximity dropped from dataframe \\nEncoding completed.\\n')\n",
    "        \n",
    "        return housing.drop(['ocean_proximity'], axis=1)\n",
    "\n",
    "\n",
    "class SelectAttributes(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, housing):\n",
    "        print('Computing correlation matrix ...')\n",
    "        \n",
    "        corr_matrix = housing.corr()\n",
    "        \n",
    "        print('Correlations for median_house_value')\n",
    "        print(corr_matrix['median_house_value'].apply(abs).sort_values(ascending=False))\n",
    "        \n",
    "        corr_matrix['median_house_value'].apply(abs).sort_values(ascending=False)\n",
    "        columns = housing.columns\n",
    "        selected_columns = []\n",
    "        print('Selecting most important columns...')\n",
    "        # corr_threshold = 0.13\n",
    "        corr_threshold=float(input('\\nEnter the correlation threshold\\n(0 - to select all columns \\n0.13 - to select highly correlated columns  \\n:)'))\n",
    "        \n",
    "        for col in columns:\n",
    "            try:\n",
    "                if abs(corr_matrix[col]['median_house_value']) > corr_threshold:\n",
    "                    selected_columns.append(col)\n",
    "            except KeyError:\n",
    "                pass\n",
    "                \n",
    "        print('Completed selecting important columns\\n')\n",
    "        \n",
    "        return housing[selected_columns]\n",
    "\n",
    "\n",
    "class ApplyModel(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, housing_selected):\n",
    "        print('Applying train-test-split on housing data...')\n",
    "        \n",
    "        X, y = housing_selected.drop([\"median_house_value\"],axis=1), housing['median_house_value']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        print('Train-test-split completed.\\n')\n",
    "        print('Scaling values...')\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        print('Scaling completed.\\n')\n",
    "        print('Applying RandomForestRegressor \\nApplying RandomizedSearchCV')\n",
    "\n",
    "        param_grid=[\n",
    "            {\n",
    "             'n_estimators': randint(low=1, high=200),\n",
    "             'max_features': randint(low=1, high=8),\n",
    "            }\n",
    "        ]\n",
    "        rfr = RandomForestRegressor()\n",
    "        clf = RandomizedSearchCV(rfr, param_grid, cv=5, n_iter=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "        print('Training the Model, Please wait, this might take a moment...')\n",
    "        \n",
    "        clf.fit(X_train.values, y_train.values)\n",
    "\n",
    "        print('Model Training completed.\\n')\n",
    "\n",
    "        print('Printing estimator results : \\n')\n",
    "        cvres = clf.cv_results_\n",
    "        for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "            print(np.sqrt(-mean_score), params)\n",
    "\n",
    "        print('\\nScore of the best estimator is ')\n",
    "        print(clf.best_estimator_.score(X.values,y.values))\n",
    "        return clf.best_estimator_.score(X.values,y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "957d35e6-547f-48e8-8bf2-e04fb3351620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing na values...\n",
      "Imputed na values.\n",
      "\n",
      "OneHotEncoding column, ocean_proximity ...\n",
      "New Columns added \n",
      "ocean_proximity dropped from dataframe \n",
      "Encoding completed.\n",
      "\n",
      "Computing correlation matrix ...\n",
      "Correlations for median_house_value\n",
      "median_house_value    1.000000\n",
      "median_income         0.688075\n",
      "INLAND                0.484859\n",
      "<1H OCEAN             0.256617\n",
      "NEAR BAY              0.160284\n",
      "latitude              0.144160\n",
      "ISLAND                0.141862\n",
      "total_rooms           0.134153\n",
      "housing_median_age    0.105623\n",
      "households            0.065843\n",
      "total_bedrooms        0.049457\n",
      "longitude             0.045967\n",
      "population            0.024650\n",
      "NEAR OCEAN            0.023416\n",
      "Name: median_house_value, dtype: float64\n",
      "Selecting most important columns...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the correlation threshold\n",
      "(0 - to select all columns \n",
      "0.13 - to select highly correlated columns  \n",
      ":) 0.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed selecting important columns\n",
      "\n",
      "Applying train-test-split on housing data...\n",
      "Train-test-split completed.\n",
      "\n",
      "Scaling values...\n",
      "Scaling completed.\n",
      "\n",
      "Applying RandomForestRegressor \n",
      "Applying RandomizedSearchCV\n",
      "Training the Model, Please wait, this might take a moment...\n",
      "Model Training completed.\n",
      "\n",
      "Printing estimator results : \n",
      "\n",
      "66057.40527209028 {'max_features': 5, 'n_estimators': 49}\n",
      "65788.31477948448 {'max_features': 6, 'n_estimators': 128}\n",
      "64969.90571395005 {'max_features': 2, 'n_estimators': 118}\n",
      "64962.40893134692 {'max_features': 2, 'n_estimators': 168}\n",
      "65161.21371610694 {'max_features': 4, 'n_estimators': 195}\n",
      "65617.70144778489 {'max_features': 5, 'n_estimators': 133}\n",
      "64816.087953100214 {'max_features': 2, 'n_estimators': 193}\n",
      "65939.886939182 {'max_features': 7, 'n_estimators': 142}\n",
      "66108.8284105395 {'max_features': 7, 'n_estimators': 98}\n",
      "66305.36030735272 {'max_features': 7, 'n_estimators': 52}\n",
      "\n",
      "Score of the best estimator is \n",
      "0.9095549448330557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9095549448330557"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('Imputer', NaImputer()),\n",
    "        ('Encoder', FeatureEncoder()),\n",
    "        ('Attribute Selector', SelectAttributes()),\n",
    "        ('RandomForestRegressor with RandomizedSearchCV', ApplyModel())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit_transform(housing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(public_env)",
   "language": "python",
   "name": "public_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
